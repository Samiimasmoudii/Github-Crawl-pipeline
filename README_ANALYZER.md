# Repository Analyzer Tool

A comprehensive standalone tool for analyzing repositories from data files, detecting LLM-generated content, and categorizing repositories based on their LLM score.

## 🚀 Features

- **Multi-format Support**: Handles JSON, XML, and CSV data files
- **Interactive Interface**: User-friendly menu for file selection and configuration
- **Repository Cloning**: Automatically clones repositories for analysis
- **LLM Detection**: Scans code files for LLM-generated content using keyword detection
- **Smart Categorization**: 
  - **Accepted** (score < 20): Little to no LLM content
  - **Pending** (score 20-50): Requires manual verification
  - **Rejected** (score > 50): High LLM content detected
- **File Extraction**: Extracts target files from ALL repositories and organizes by category
- **Comprehensive Reporting**: Detailed JSON reports with statistics

## 📋 Requirements

- Python 3.7+
- Git (for repository cloning)
- Required directories: `Data/` (input), `output/` (results)

## 🎯 Usage

### Basic Usage
```bash
python repository_analyzer.py
```

### With Custom Directories
```bash
python repository_analyzer.py --data-dir /path/to/data --output-dir /path/to/output
```

## 📊 Interactive Workflow

1. **File Selection**: Choose from available JSON/XML/CSV files
2. **Repository Count**: Specify how many repositories to analyze (default: 20)
3. **File Extensions**: Choose target file types (.py, .java, .js, etc.)
4. **Analysis**: Tool clones repositories and scans for LLM keywords
5. **Results**: Repositories are categorized and files are extracted

## 🏗️ Data File Formats

### JSON Format (SEART-style)
```json
{
  "parameters": {...},
  "items": [
    {
      "name": "owner/repository",
      "mainLanguage": "Python",
      "stargazers": 10,
      "description": "Repository description",
      "createdAt": "2025-01-01T00:00:00"
    }
  ]
}
```

### CSV Format
```csv
name,mainLanguage,stargazers,description,createdAt
owner/repo,Python,10,Description,2025-01-01
```

## 📁 Output Structure

```
output/
├── repository_scores.json          # Detailed analysis results
├── extracted_files/               # Extracted source files (categorized)
│   ├── accepted/                  # Low LLM content (score < 20)
│   │   ├── owner_repo1/
│   │   └── owner_repo2/
│   ├── pending/                   # Medium LLM content (score 20-50)
│   │   ├── owner_repo3/
│   │   └── owner_repo4/
│   ├── rejected/                  # High LLM content (score > 50)
│   │   ├── owner_repo5/
│   │   └── owner_repo6/
│   └── failed/                    # Failed to clone
│       ├── owner_repo7/
│       │   └── repository_info.txt
│       └── owner_repo8/
│           └── repository_info.txt
└── logs/                          # Processing logs
```

## 🤖 LLM Keywords Detected

The tool searches for these LLM-related keywords:
- AI Models: `chatgpt`, `claude`, `llama`, `mistral`, `gpt-4`, `gemini`
- AI Services: `openai`, `anthropic`, `huggingface`
- Generation terms: `ai-generated`, `auto-generated`, `machine-generated`
- And more...

## 📊 Scoring System

- **+10 points** per keyword found in source code
- **+5 points** per keyword found in README files
- **Score < 20**: Accepted (minimal LLM content)
- **Score 20-50**: Pending (manual review needed)
- **Score > 50**: Rejected (high LLM content)

## 🎛️ Configuration

The tool automatically imports settings from `config.py` if available, or uses built-in defaults:

```python
LLM_KEYWORDS = [
    "chatgpt", "claude", "llama", "mistral", "gpt-4", "gemini", "copilot",
    "openai", "anthropic", "huggingface", "ai-generated", "generated by",
    "ai-assisted", "machine-generated"
]
```

## 📈 Example Output

```
📊 ANALYSIS SUMMARY
============================================================
✅ Accepted:       15 repositories (score < 20)
⏳ Pending:         3 repositories (score 20-50)
❌ Rejected:        2 repositories (score > 50)
💥 Failed clones:   0 repositories
📊 Total processed: 20 repositories

📁 Files saved to:
   📄 Results: output/repository_scores.json
   📂 Extracted files: output/extracted_files

📈 Average LLM Score: 12.5

🔤 Most common LLM keywords:
   chatgpt: 3 repositories
   openai: 2 repositories
   ai-generated: 1 repositories
```

## 🔧 Advanced Features

### Custom Extensions
Specify any file extensions you want to analyze:
```
.py .java .js .cpp .cs .go .rs .swift
```

### Timeout Handling
- Repository cloning timeout: 5 minutes
- Graceful handling of failed clones
- Progress tracking for large datasets

### Error Recovery
- Skips unreadable files
- Continues analysis if individual repositories fail
- Comprehensive error logging

## 🎨 Example Usage Session

```bash
$ python repository_analyzer.py

🚀 REPOSITORY ANALYZER
============================================================
This tool analyzes repositories for LLM-generated content
and categorizes them based on detected keywords.

============================================================
📁 AVAILABLE DATA FILES
============================================================
 1. seart_june2025.json                   (1.4 MB)
 2. repositories_2024.csv                 (0.8 MB)

============================================================

Select a file (1-2): 1

📂 Loading data from: seart_june2025.json

📊 Found 1250 repositories in the dataset

How many repositories would you like to analyze? (Suggested: 20): 25

📄 Which file types would you like to extract?
Common extensions: .py (Python), .java (Java), .js (JavaScript), .cpp (C++), .cs (C#), .go (Go)
Example: .py .java .js

Enter file extensions (space-separated): .py .js

🎯 Configuration:
   📊 Repositories to analyze: 25
   📄 File extensions: .py, .js
   🤖 LLM keywords: 22 keywords

🚀 Start analysis? (y/N): y

🔍 ANALYZING 25 REPOSITORIES
============================================================

[1/25] Processing: user/awesome-project
   🤖 LLM Score: 0
   📂 Category: Accepted
   📁 Extracted 15 files

[2/25] Processing: dev/chatgpt-helper
   🤖 LLM Score: 85
   📂 Category: Rejected
   🔍 Keywords found: chatgpt, openai, ai-generated

...
```

## 🛠️ Troubleshooting

### Common Issues

1. **Git not found**: Ensure Git is installed and in PATH
2. **Permission errors**: Check write permissions for output directory
3. **Memory issues**: Reduce number of repositories for large datasets
4. **Network timeouts**: Check internet connection for repository cloning

### Tips

- Start with a small number of repositories (10-20) for testing
- Ensure sufficient disk space for cloned repositories
- Use specific file extensions to reduce processing time
- Monitor the temp_repos directory during analysis

## 📝 License

This tool is part of the GitHub Crawl Pipeline project and follows the same licensing terms. 