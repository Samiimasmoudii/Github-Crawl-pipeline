#!/usr/bin/env python3
"""
Comprehensive Repository Analyzer Tool
=====================================

This tool analyzes repository data from files, clones repositories,
searches for LLM keywords, scores repositories, and categorizes them.

Features:
- Lists available data files (JSON/XML/CSV)
- User-friendly interface for file selection
- Repository cloning and analysis
- LLM keyword detection and scoring
- Automatic categorization (Accepted/Pending/Rejected)
- File extraction based on user preferences
"""

import os
import json
import csv
import xml.etree.ElementTree as ET
import subprocess
import shutil
import re
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any
import argparse
import sys

# Import existing configuration from config.py
try:
    from config import Config
    LLM_KEYWORDS = Config.LLM_KEYWORDS
    OUTPUT_DIR = Config.OUTPUT_DIR
    EXTRACTED_FILES_DIR = Config.EXTRACTED_FILES_DIR
except ImportError:
    # Fallback configuration
    LLM_KEYWORDS = [
        "chatgpt", "claude", "llama", "mistral", "gpt-4", "gemini", "copilot",
        "openai", "anthropic", "huggingface", "ai-generated", "generated by",
        "ai-assisted", "machine-generated", "gpt-3", "gpt-4", "gpt-3.5",
        "artificial intelligence", "neural network", "deep learning",
        "machine learning", "auto-generated", "automatically generated"
    ]
    OUTPUT_DIR = "output"
    EXTRACTED_FILES_DIR = os.path.join(OUTPUT_DIR, "extracted_files")

class RepositoryAnalyzer:
    def __init__(self):
        self.data_dir = "Data"
        self.output_dir = OUTPUT_DIR
        self.extracted_files_dir = EXTRACTED_FILES_DIR
        self.results_file = os.path.join(self.output_dir, "repository_scores.json")
        self.logs_dir = os.path.join(self.output_dir, "logs")
        self.ensure_directories()
        self.setup_logging()
        
    def ensure_directories(self):
        """Create necessary directories"""
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs(self.extracted_files_dir, exist_ok=True)
        os.makedirs(self.logs_dir, exist_ok=True)
        
        # Create category subdirectories
        for category in ['accepted', 'pending', 'rejected', 'failed']:
            os.makedirs(os.path.join(self.extracted_files_dir, category), exist_ok=True)
    
    def setup_logging(self):
        """Setup logging configuration"""
        # Create timestamp for log files
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # Setup main logger
        self.logger = logging.getLogger('RepositoryAnalyzer')
        self.logger.setLevel(logging.INFO)
        
        # Clear any existing handlers
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # File handler for general logs
        log_file = os.path.join(self.logs_dir, f"analysis_{timestamp}.log")
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # Error log handler
        error_log_file = os.path.join(self.logs_dir, f"errors_{timestamp}.log")
        error_handler = logging.FileHandler(error_log_file, encoding='utf-8')
        error_handler.setLevel(logging.ERROR)
        
        # Console handler (keep console output)
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # Formatter
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        error_handler.setFormatter(formatter)
        
        # Console formatter (simpler)
        console_formatter = logging.Formatter('%(message)s')
        console_handler.setFormatter(console_formatter)
        
        # Add handlers
        self.logger.addHandler(file_handler)
        self.logger.addHandler(error_handler)
        self.logger.addHandler(console_handler)
        
        # Log setup completion
        self.logger.info("="*60)
        self.logger.info("Repository Analyzer Started")
        self.logger.info(f"Log file: {log_file}")
        self.logger.info(f"Error log: {error_log_file}")
        self.logger.info("="*60)
        
    def list_available_files(self) -> List[str]:
        """List all available JSON/XML/CSV files in the Data directory"""
        if not os.path.exists(self.data_dir):
            self.logger.error(f"âŒ Data directory '{self.data_dir}' not found!")
            return []
        
        supported_extensions = ['.json', '.xml', '.csv']
        files = []
        
        for file in os.listdir(self.data_dir):
            if any(file.lower().endswith(ext) for ext in supported_extensions):
                file_path = os.path.join(self.data_dir, file)
                file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
                files.append((file, file_size))
        
        return files
    
    def display_file_menu(self, files: List[Tuple[str, float]]) -> Optional[str]:
        """Display available files and get user selection"""
        if not files:
            self.logger.error("âŒ No data files found!")
            return None
        
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“ AVAILABLE DATA FILES")
        self.logger.info("="*60)
        
        for i, (filename, size) in enumerate(files, 1):
            self.logger.info(f"{i:2d}. {filename:<40} ({size:.1f} MB)")
        
        self.logger.info("\n" + "="*60)
        
        while True:
            try:
                choice = input(f"\nSelect a file (1-{len(files)}): ").strip()
                if choice.lower() == 'q':
                    return None
                
                idx = int(choice) - 1
                if 0 <= idx < len(files):
                    return files[idx][0]
                else:
                    self.logger.warning(f"âŒ Invalid choice! Please enter 1-{len(files)}")
            except ValueError:
                self.logger.warning("âŒ Invalid input! Please enter a number or 'q' to quit")
    
    def load_data_file(self, filename: str) -> List[Dict]:
        """Load data from JSON/XML/CSV file"""
        file_path = os.path.join(self.data_dir, filename)
        
        try:
            if filename.lower().endswith('.json'):
                return self._load_json_file(file_path)
            elif filename.lower().endswith('.xml'):
                return self._load_xml_file(file_path)
            elif filename.lower().endswith('.csv'):
                return self._load_csv_file(file_path)
            else:
                self.logger.error(f"âŒ Unsupported file format: {filename}")
                return []
        except Exception as e:
            self.logger.error(f"âŒ Error loading file {filename}: {e}")
            return []
    
    def _load_json_file(self, file_path: str) -> List[Dict]:
        """Load JSON file (handles both array and object with items array)"""
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if isinstance(data, list):
            return data
        elif isinstance(data, dict):
            # Handle SEART-style JSON with parameters and items
            if 'items' in data:
                return data['items']
            else:
                return [data]
        else:
            self.logger.error(f"âŒ Unexpected JSON structure in {file_path}")
            return []
    
    def _load_xml_file(self, file_path: str) -> List[Dict]:
        """Load XML file"""
        tree = ET.parse(file_path)
        root = tree.getroot()
        
        repositories = []
        for repo in root.findall('.//repository'):
            repo_dict = {}
            for elem in repo:
                repo_dict[elem.tag] = elem.text
            repositories.append(repo_dict)
        
        return repositories
    
    def _load_csv_file(self, file_path: str) -> List[Dict]:
        """Load CSV file"""
        repositories = []
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                repositories.append(row)
        
        return repositories
    
    def get_repository_info(self, repo_data: Dict) -> Dict:
        """Extract repository information from data"""
        # Handle different data formats
        repo_info = {
            'name': repo_data.get('name', repo_data.get('full_name', '')),
            'full_name': repo_data.get('name', repo_data.get('full_name', '')),
            'description': repo_data.get('description', ''),
            'language': repo_data.get('mainLanguage', repo_data.get('language', '')),
            'stars': int(repo_data.get('stargazers', repo_data.get('stars', 0))),
            'url': f"https://github.com/{repo_data.get('name', repo_data.get('full_name', ''))}",
            'created_at': repo_data.get('createdAt', repo_data.get('created_at', '')),
            'topics': repo_data.get('topics', [])
        }
        
        return repo_info
    
    def get_user_preferences(self, total_repos: int) -> Tuple[int, List[str]]:
        """Get user preferences for number of repositories and file extensions"""
        self.logger.info(f"\nğŸ“Š Found {total_repos} repositories in the dataset")
        
        # Ask for number of repositories
        while True:
            try:
                suggested = min(20, total_repos)
                response = input(f"\nHow many repositories would you like to analyze? (Suggested: {suggested}): ").strip()
                
                if not response:
                    num_repos = suggested
                    break
                
                num_repos = int(response)
                if 1 <= num_repos <= total_repos:
                    break
                else:
                    self.logger.warning(f"âŒ Please enter a number between 1 and {total_repos}")
            except ValueError:
                self.logger.warning("âŒ Invalid input! Please enter a number")
        
        # Ask for file extensions
        self.logger.info("\nğŸ“„ Which file types would you like to extract?")
        self.logger.info("Common extensions: .py (Python), .java (Java), .js (JavaScript), .cpp (C++), .cs (C#), .go (Go)")
        self.logger.info("Example: .py .java .js")
        
        while True:
            extensions_input = input("Enter file extensions (space-separated): ").strip()
            if extensions_input:
                extensions = [ext.strip() for ext in extensions_input.split()]
                # Ensure extensions start with dot
                extensions = [ext if ext.startswith('.') else f'.{ext}' for ext in extensions]
                break
            else:
                self.logger.warning("âŒ Please enter at least one file extension")
        
        return num_repos, extensions
    
    def clone_repository(self, repo_url: str, repo_name: str) -> Optional[str]:
        """Clone a repository to a temporary directory"""
        temp_dir = os.path.join(self.output_dir, "temp_repos")
        os.makedirs(temp_dir, exist_ok=True)
        
        # Clean repository name for folder
        safe_name = re.sub(r'[^\w\-_.]', '_', repo_name.replace('/', '_'))
        repo_path = os.path.join(temp_dir, safe_name)
        
        # Remove existing directory if it exists
        if os.path.exists(repo_path):
            shutil.rmtree(repo_path)
        
        try:
            # Clone repository
            result = subprocess.run(
                ['git', 'clone', '--depth', '1', repo_url, repo_path],
                capture_output=True,
                text=True,
                timeout=300  # 5 minutes timeout
            )
            
            if result.returncode == 0:
                self.logger.info(f"âœ… Successfully cloned {repo_name}")
                return repo_path
            else:
                self.logger.error(f"âŒ Failed to clone {repo_name}: {result.stderr}")
                return None
                
        except subprocess.TimeoutExpired:
            self.logger.error(f"â° Timeout cloning {repo_name}")
            return None
        except Exception as e:
            self.logger.error(f"âŒ Error cloning {repo_name}: {e}")
            return None
    
    def scan_repository_for_llm_keywords(self, repo_path: str, file_extensions: List[str]) -> Tuple[int, List[str]]:
        """Scan repository files for LLM keywords"""
        score = 0
        found_keywords = []
        
        for root, dirs, files in os.walk(repo_path):
            # Skip .git directory
            if '.git' in dirs:
                dirs.remove('.git')
            
            for file in files:
                if any(file.endswith(ext) for ext in file_extensions):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            content = f.read().lower()
                            
                        for keyword in LLM_KEYWORDS:
                            if keyword in content:
                                score += 10
                                if keyword not in found_keywords:
                                    found_keywords.append(keyword)
                                    
                    except Exception as e:
                        # Skip files that can't be read
                        continue
        
        # Also check README files
        readme_files = ['README.md', 'README.txt', 'README.rst', 'README']
        for readme in readme_files:
            readme_path = os.path.join(repo_path, readme)
            if os.path.exists(readme_path):
                try:
                    with open(readme_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read().lower()
                        
                    for keyword in LLM_KEYWORDS:
                        if keyword in content:
                            score += 5  # Lower score for README mentions
                            if keyword not in found_keywords:
                                found_keywords.append(keyword)
                                
                except Exception:
                    continue
        
        return score, found_keywords
    
    def extract_target_files(self, repo_path: str, repo_name: str, file_extensions: List[str], category: str) -> List[str]:
        """Extract target files from repository into categorized folders"""
        # Clean repository name for folder
        safe_name = re.sub(r'[^\w\-_.]', '_', repo_name.replace('/', '_'))
        
        # Create category-based directory structure
        category_dir = os.path.join(self.extracted_files_dir, category.lower())
        output_repo_dir = os.path.join(category_dir, safe_name)
        os.makedirs(output_repo_dir, exist_ok=True)
        
        extracted_files = []
        
        for root, dirs, files in os.walk(repo_path):
            # Skip .git directory
            if '.git' in dirs:
                dirs.remove('.git')
            
            for file in files:
                if any(file.endswith(ext) for ext in file_extensions):
                    src_path = os.path.join(root, file)
                    
                    # Create relative path structure
                    rel_path = os.path.relpath(src_path, repo_path)
                    dst_path = os.path.join(output_repo_dir, rel_path)
                    
                    # Create directory if needed
                    os.makedirs(os.path.dirname(dst_path), exist_ok=True)
                    
                    try:
                        shutil.copy2(src_path, dst_path)
                        extracted_files.append(rel_path)
                    except Exception as e:
                        self.logger.warning(f"âš ï¸  Could not copy {rel_path}: {e}")
        
        self.logger.info(f"Extracted {len(extracted_files)} files for {repo_name}")
        return extracted_files
    
    def categorize_repository(self, score: int) -> str:
        """Categorize repository based on LLM score"""
        if score < 20:
            return "Accepted"
        elif score <= 50:
            return "Pending"
        else:
            return "Rejected"
    
    def analyze_repositories(self, repositories: List[Dict], num_repos: int, file_extensions: List[str]):
        """Main analysis function"""
        self.logger.info(f"\nğŸ” ANALYZING {num_repos} REPOSITORIES")
        self.logger.info("="*60)
        
        results = {
            'analysis_date': datetime.now().isoformat(),
            'total_repositories': num_repos,
            'file_extensions': file_extensions,
            'repositories': [],
            'summary': {
                'accepted': 0,
                'pending': 0,
                'rejected': 0,
                'failed_clones': 0
            }
        }
        
        for i, repo_data in enumerate(repositories[:num_repos], 1):
            repo_info = self.get_repository_info(repo_data)
            repo_name = repo_info['full_name']
            
            self.logger.info(f"\n[{i}/{num_repos}] Processing: {repo_name}")
            
            # Clone repository
            repo_path = self.clone_repository(repo_info['url'], repo_name)
            if not repo_path:
                self.logger.error(f"âŒ Failed to clone {repo_name}")
                
                # Still record the failed repository information
                repo_result = {
                    'name': repo_name,
                    'url': repo_info['url'],
                    'description': repo_info['description'],
                    'language': repo_info['language'],
                    'stars': repo_info['stars'],
                    'llm_score': -1,  # Special score for failed clones
                    'category': 'Failed',
                    'found_keywords': [],
                    'extracted_files': [],
                    'error': 'Failed to clone repository'
                }
                
                # Create a failed directory entry
                safe_name = re.sub(r'[^\w\-_.]', '_', repo_name.replace('/', '_'))
                failed_repo_dir = os.path.join(self.extracted_files_dir, 'failed', safe_name)
                os.makedirs(failed_repo_dir, exist_ok=True)
                
                # Write repository info to a text file
                info_file = os.path.join(failed_repo_dir, 'repository_info.txt')
                with open(info_file, 'w', encoding='utf-8') as f:
                    f.write(f"Repository: {repo_name}\n")
                    f.write(f"URL: {repo_info['url']}\n")
                    f.write(f"Language: {repo_info['language']}\n")
                    f.write(f"Stars: {repo_info['stars']}\n")
                    f.write(f"Description: {repo_info['description']}\n")
                    f.write(f"Status: Failed to clone\n")
                    f.write(f"Timestamp: {datetime.now().isoformat()}\n")
                
                results['repositories'].append(repo_result)
                results['summary']['failed_clones'] += 1
                self.logger.warning(f"   ğŸ“ Recorded repository info in failed/")
                continue
            
            try:
                # Scan for LLM keywords
                score, found_keywords = self.scan_repository_for_llm_keywords(repo_path, file_extensions)
                category = self.categorize_repository(score)
                
                self.logger.info(f"   ğŸ¤– LLM Score: {score}")
                self.logger.info(f"   ğŸ“‚ Category: {category}")
                if found_keywords:
                    self.logger.info(f"   ğŸ” Keywords found: {', '.join(found_keywords[:5])}")
                
                repo_result = {
                    'name': repo_name,
                    'url': repo_info['url'],
                    'description': repo_info['description'],
                    'language': repo_info['language'],
                    'stars': repo_info['stars'],
                    'llm_score': score,
                    'category': category,
                    'found_keywords': found_keywords,
                    'extracted_files': []
                }
                
                # Extract files from ALL repositories (including rejected ones)
                extracted_files = self.extract_target_files(repo_path, repo_name, file_extensions, category)
                repo_result['extracted_files'] = extracted_files
                self.logger.info(f"   ğŸ“ Extracted {len(extracted_files)} files to {category.lower()}/")
                
                results['repositories'].append(repo_result)
                results['summary'][category.lower()] += 1
                
            finally:
                # Clean up cloned repository
                if os.path.exists(repo_path):
                    shutil.rmtree(repo_path)
        
        # Save results
        with open(self.results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        self.display_summary(results)
    
    def display_summary(self, results: Dict):
        """Display analysis summary"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“Š ANALYSIS SUMMARY")
        self.logger.info("="*60)
        
        summary = results['summary']
        total_processed = summary['accepted'] + summary['pending'] + summary['rejected']
        
        self.logger.info(f"âœ… Accepted:      {summary['accepted']:3d} repositories (score < 20)")
        self.logger.info(f"â³ Pending:       {summary['pending']:3d} repositories (score 20-50)")
        self.logger.info(f"âŒ Rejected:      {summary['rejected']:3d} repositories (score > 50)")
        self.logger.info(f"ğŸ’¥ Failed clones: {summary['failed_clones']:3d} repositories")
        self.logger.info(f"ğŸ“Š Total processed: {total_processed:3d} repositories")
        
        self.logger.info(f"\nğŸ“ Files saved to:")
        self.logger.info(f"   ğŸ“„ Results: {self.results_file}")
        self.logger.info(f"   ğŸ“‚ Extracted files: {self.extracted_files_dir}")
        self.logger.info(f"      â”œâ”€â”€ accepted/    (score < 20)")
        self.logger.info(f"      â”œâ”€â”€ pending/     (score 20-50)")
        self.logger.info(f"      â”œâ”€â”€ rejected/    (score > 50)")
        self.logger.info(f"      â””â”€â”€ failed/      (clone failed)")
        self.logger.info(f"   ğŸ“ Logs: {self.logs_dir}")
        
        # Show some statistics
        if results['repositories']:
            scores = [r['llm_score'] for r in results['repositories']]
            avg_score = sum(scores) / len(scores)
            self.logger.info(f"\nğŸ“ˆ Average LLM Score: {avg_score:.1f}")
            
            # Show top keywords
            all_keywords = {}
            for repo in results['repositories']:
                for keyword in repo['found_keywords']:
                    all_keywords[keyword] = all_keywords.get(keyword, 0) + 1
            
            if all_keywords:
                self.logger.info(f"\nğŸ”¤ Most common LLM keywords:")
                sorted_keywords = sorted(all_keywords.items(), key=lambda x: x[1], reverse=True)
                for keyword, count in sorted_keywords[:5]:
                    self.logger.info(f"   {keyword}: {count} repositories")
    
    def run(self):
        """Main execution function"""
        self.logger.info("ğŸš€ REPOSITORY ANALYZER")
        self.logger.info("="*60)
        self.logger.info("This tool analyzes repositories for LLM-generated content")
        self.logger.info("and categorizes them based on detected keywords.")
        
        # List available files
        files = self.list_available_files()
        if not files:
            return
        
        # Get user file selection
        selected_file = self.display_file_menu(files)
        if not selected_file:
            self.logger.info("ğŸ‘‹ Goodbye!")
            return
        
        self.logger.info(f"\nğŸ“‚ Loading data from: {selected_file}")
        
        # Load data
        repositories = self.load_data_file(selected_file)
        if not repositories:
            self.logger.error("âŒ No repositories found in the selected file!")
            return
        
        # Get user preferences
        num_repos, file_extensions = self.get_user_preferences(len(repositories))
        
        self.logger.info(f"\nğŸ¯ Configuration:")
        self.logger.info(f"   ğŸ“Š Repositories to analyze: {num_repos}")
        self.logger.info(f"   ğŸ“„ File extensions: {', '.join(file_extensions)}")
        self.logger.info(f"   ğŸ¤– LLM keywords: {len(LLM_KEYWORDS)} keywords")
        
        # Confirm before starting
        confirm = input("\nğŸš€ Start analysis? (y/N): ").strip().lower()
        if confirm != 'y':
            self.logger.info("ğŸ‘‹ Analysis cancelled!")
            return
        
        # Run analysis
        self.analyze_repositories(repositories, num_repos, file_extensions)


def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(description='Repository Analyzer Tool')
    parser.add_argument('--data-dir', default='Data', help='Directory containing data files')
    parser.add_argument('--output-dir', default='output', help='Output directory')
    
    args = parser.parse_args()
    
    analyzer = RepositoryAnalyzer()
    analyzer.data_dir = args.data_dir
    analyzer.output_dir = args.output_dir
    analyzer.extracted_files_dir = os.path.join(args.output_dir, 'extracted_files')
    analyzer.results_file = os.path.join(args.output_dir, 'repository_scores.json')
    
    try:
        analyzer.run()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  Analysis interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 