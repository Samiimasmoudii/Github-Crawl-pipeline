# GitHub Code Extraction Pipeline - Documentation

## 📊 **Current Status: Phase 1 Complete** ✅

A modular pipeline that  discovers newly created GitHub repositories using GH Archive data and extracts source code files via GitHub API, with basic LLM filtering.

---

## 🏗️ **Pipeline Architecture**

### **Data Flow**
```
GH Archive CreateEvents → Repository Discovery → GitHub API → File Extraction → Output
```

### **File Structure**
```
Github Crawl pipeline/
├── 📋 PIPELINE_DOCUMENTATION.md      # This guide
├── 📋 Project_description.md          # Original project description  
├── 📋 Pipeline schema.txt             # Pipeline flow diagram
├── 📋 .env                           # GitHub token configuration
├── 📋 requirements.txt                # Python dependencies    
│
├── ⚙️ config.py                       # Central configuration
├── 🔄 gharchive_client.py             # GH Archive integration
├── 🔍 repository_finder.py            # Repository discovery
├── 🌐 github_client.py                # File extraction
├── 🧪 mini_pipeline_test.py           # End-to-end testing
│
└── 📂 output/                         # Pipeline outputs
    ├── extracted_files/               # Source code files
    ├── sample_metadata.json           # Metadata
    └── logs/                          # Processing logs
```

---

## 🔧 **Component Overview**

### **1. Config (`config.py`)**
**What it does**: Manages all pipeline settings and parameters in one place
**Output**: Configuration values for dates, file types, API limits, LLM thresholds

### **2. GHArchiveClient (`gharchive_client.py`)**
**What it does**: Downloads and parses GitHub Archive hourly data files
**Output**: Stream of GitHub events (CreateEvent, PushEvent, etc.) from archive data

### **3. RepositoryFinder (`repository_finder.py`)**
**What it does**: Finds newly created repositories using CreateEvents and filters them
**Output**: List of repository candidates that meet language and quality criteria

### **4. GitHubAPIClient (`github_client.py`)**
**What it does**: Connects to GitHub API to get repository details and download files
**Output**: Repository metadata and actual source code file contents

### **5. MiniPipelineTest (`mini_pipeline_test.py`)**
**What it does**: Runs the complete pipeline end-to-end for testing
**Output**: Sample extracted files saved to disk + test results summary

---

## 📊 **Current Performance**

**Latest Test Results**:
```
Input:  1 hour GH Archive data (2024-01-01 hour 12)
Discovery: 5,131 newly created repositories
Filtering: Language + LLM score + star count
Output: 5 source code files extracted
```

## 🎯 **Key Design Decisions**

1. **CreateEvents vs PushEvents**: Use CreateEvents for efficient repository discovery (no API calls needed)
2. **Modular Architecture**: Each component has single responsibility and works independently
3. **Configuration-Driven**: All settings centralized for easy adjustment

## ✅ **Phase 1 Complete**

- [x] GH Archive data download and parsing
- [x] CreateEvent-based repository discovery  
- [x] Creation date filtering (no API calls required)
- [x] GitHub API file extraction
- [x] Basic LLM keyword detection
- [x] End-to-end pipeline testing

## 🤖 **Current LLM Filtering Implementation**

### **Where LLM Filtering Happens:**

**1. Repository Discovery Phase** (`repository_finder.py`):
- **Repository descriptions** - scanned during CreateEvents processing
- **Commit messages** - scanned from GH Archive PushEvents

**2. Filtering Locations:**
- `_calculate_llm_score_from_description()` - scans repo descriptions
- `_calculate_llm_score()` - scans commit messages from archive data
- `filter_target_repositories()` - applies thresholds (score < 20 for strict filtering)

**3. Keywords Being Detected** (`config.py`):
```python
LLM_KEYWORDS = [
    "chatgpt", "claude", "llama", "mistral", "gpt-4", "gemini", "copilot",
    "openai", "anthropic", "huggingface", "ai-generated", "generated by",
    "ai-assisted", "machine-generated"
]
```

**4. Scoring System:**
- **+10 points** per keyword found in text
- **Score < 20**: Repository accepted (strict filtering)
- **Score < 50**: Repository accepted (basic filtering)
- **Score ≥ 50**: Repository rejected

### **What's Currently Scanned:**
- ✅ **Repository descriptions** (from CreateEvents)
- ✅ **Commit messages** (from GH Archive)
- ❌ **NOT actual source code files** (Phase 2)

### **Current Limitations:**
- **Repository-level only** - doesn't scan individual files
- **Simple keyword matching** - no advanced pattern detection
- **Basic scoring** - just counts keyword occurrences
- **No file content analysis** - that's the next phase

---

## 🚀 **Phase 2: Advanced LLM Detection (Next)**

- obtain the list of repos from seart created after cutoff dates, clone them, and then verify which files are totally human-generated
- cross-validate with the PRs that contained those commits, maybe LLM usage is mentioned in the PR description
-Investigate and lower the API usage by removing some events from the archive ..

Current: Basic keyword scanning in repository descriptions and commit messages
Next: Advanced code-level analysis to detect LLM-generated source code patterns

---

*Pipeline Documentation - Phase 1 Complete* 