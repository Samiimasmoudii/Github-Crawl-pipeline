# GitHub Code Extraction Pipeline - Detailed Project Description

## **Project Overview**

A modular, configurable pipeline designed to extract clean, non-LLM-generated source code files from GitHub repositories. The system ensures data integrity for machine learning training purposes by filtering out code that may have been generated by or trained on Large Language Models.

## **Core Objectives**

### **Primary Goal**
Extract high-quality source code files from GitHub repositories that were committed after a specified date threshold, ensuring the code predates LLM training data to avoid contamination.

### **Quality Assurance Goals**
- **Temporal Filtering**: Only collect code committed after user-specified dates
- **LLM Contamination Prevention**: Exclude code that shows evidence of LLM generation
- **Quality Filtering**: Target repositories with minimum community validation (10+ stars)
- **Format Preservation**: Maintain original file extensions and structure

## **Technical Specifications**

### **Input Parameters**

Configuration:
  - target_date: "2023-12-31"  # Cutoff date for commits
  - languages: ["Python", "Java", "C++"]  # Programming languages
  - file_extensions: [".py", ".java", ".cpp"]  # Target file types
  - min_stars: 10  # Minimum repository stars
  - max_repos: 1000  # Maximum repositories to process


### **Repository Selection Criteria**
- **Minimum Stars**: 10+ (indicates community value)
- **Language Specificity**: Must match user-specified languages
- **Recent Activity**: Active development within reasonable timeframe
- **Size Constraints**: Limited by GitHub API rate limits
- **Accessibility**: Public repositories only

### **LLM Detection System**

#### **Keyword-Based Detection**
Monitor for mentions of:
- **AI Models**: ChatGPT, Claude, Llama, Mistral, GPT-4, Gemini, Copilot
- **AI Services**: OpenAI, Anthropic, HuggingFace, AI-generated
- **Generation Terms**: "generated by", "AI-assisted", "machine-generated"

#### **Pattern-Based Detection**
- **Comment Patterns**: Typical LLM-generated comment structures
- **Code Patterns**: Common LLM coding signatures
- **Documentation Patterns**: AI-generated documentation styles

#### **Scope of Detection**
- **File Content**: Scan actual source code and comments
- **Commit Messages**: Analyze commit descriptions
- **Repository Metadata**: Check README, issues, descriptions

### **Filtering Strategy**

#### **File-Level Filtering** 
- Analyze each file individually
- Exclude files with LLM indicators
- Preserve clean files from partially contaminated repositories

#### **Repository-Level Filtering** (Optional)
- Skip entire repositories with LLM mentions
- More conservative but potentially wasteful approach

## **Pipeline Architecture**

### **Stage 1: Repository Discovery**
```python
GitHub Search API → Filter by:
├── Language specification
├── Star count (10+)
├── Activity recency
└── Public accessibility
```

### **Stage 2: Temporal Filtering**
```python
For each repository:
├── Fetch commit history
├── Filter commits after threshold date
├── Identify modified files
└── Skip repositories with no recent commits
```

### **Stage 3: File Extraction**
```python
For each valid commit:
├── Download specified file types
├── Preserve original file structure (Optional )
├── Track file metadata
└── Skip non-code files (README, CSV, etc.)
```

### **Stage 4: LLM Detection & Scoring**
```python
For Each Repo
├── Generate LLM-score (0-100)
├── Flag suspicious files

For each extracted file:
├── Keyword scanning
├── Pattern analysis
├── Generate LLM-score (0-100)
├── Flag suspicious files
└── Log detection reasons
```

### **Stage 5: Output Generation**
```python
Generate two outputs:
├── Raw Files: Original extensions preserved
└── Metadata CSV: Comprehensive tracking
```

## **Output Specifications**

### **File Structure**
```
output/
├── extracted_files/
│   ├── repo_1/
│   │   ├── file1.py
│   │   ├── file2.java
│   │   └── file3.cpp
│   ├── repo_2/
│   │   └── ...
│   └── ...
└── metadata.csv
```

### **CSV Schema**
```csv
file_path,sha,github_url,repo_name,commit_date,author,file_size,language,llm_score,llm_flags,extraction_date
extracted_files/repo_1/file1.py,a1b2c3d4...,https://github.com/user/repo/blob/main/file1.py,user/repo,2024-01-15,john_doe,2048,Python,5,none,2024-02-01
```

### **LLM Scoring System**
- **Score Range**: 0-100 (lower is better)
- **Threshold**:    
    - Files with score > 50 Will be rejected
    - Files with score > 20 flagged for review

- **Scoring Factors**:
  - Keyword frequency: +10 per mention
  - Pattern matches: +15 per pattern
  - Commit message mentions: +25
  - Repository-level mentions: +5

## **Rate Limiting & Error Handling**

### **GitHub API Management**
- **Rate Limit**: 5000 requests/hour (authenticated)
- **Handling**: Automatic pause with countdown timer
- **Display**: "API LIMIT REACHED, CONTINUING IN 2 MINS 43 SECS..."
- **Recovery**: Automatic resumption after reset

### **Error Handling**
- **Network Errors**: Retry with exponential backoff
- **Repository Access**: Skip private/deleted repositories
- **File Access**: Log inaccessible files, continue processing
- **Corruption**: Validate file integrity, skip corrupted files

## **Modularity & Reusability**

### **Component Structure**
```python
pipeline/
├── config.py           # Configuration management
├── github_client.py    # GitHub API wrapper
├── llm_detector.py     # LLM detection logic
├── file_processor.py   # File handling utilities
├── pipeline.py         # Main orchestration
├── utils.py           # Common utilities
└── main.py            # Entry point
```

### **Configuration Options**
- **Flexible Inputs**: Date, languages, file types
- **Adjustable Thresholds**: Star counts, LLM scores
- **Extensible Detection**: Easy to add new LLM patterns
- **Output Formats**: Configurable output structure

## **Quality Assurance Features**

### **Data Integrity**
- **SHA Verification**: Ensure file integrity
- **Duplicate Detection**: Prevent duplicate extractions
- **Metadata Validation**: Verify all required fields
- **Audit Trail**: Complete processing history

### **Performance Optimization**
- **Batch Processing**: Process multiple files simultaneously
- **Caching**: Cache repository metadata
- **Resume Capability**: Restart from interruption point
- **Progress Tracking**: Real-time processing updates

## **Usage Examples**

### **Basic Extraction**
```bash
python main.py --date "2024-01-01" --language "Python" --extensions ".py"
```

### **Multi-Language Extraction**
```bash
python main.py --date "2023-12-31" --language "Java,Python,C++" --extensions ".java,.py,.cpp" --min-stars 50
```

### **Custom Configuration**
```bash
python main.py --config custom_config.yaml --output-dir /path/to/output
```
